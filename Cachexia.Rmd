---
title: "cachexia"
author: "Liangyu Yin"
date: "2022/6/18"
output: html_document
---

```{r}

library(magrittr) 

building <- TRUE

scoring  <- ! building

# so that results are repeatable.

crv$seed <- 8

# Load a dataset from file.

fname         <- "file:///F:/Desktop/dataset.csv" ## File path
crs$dataset <- read.csv(fname,
                        na.strings=c(".", "NA", "", "?"),
                        strip.white=TRUE, encoding="UTF-8")

# Build the train/validate/test datasets.

# nobs=12774 train=9580 validate=3194 test=0

set.seed(8)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.75*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) ->
crs$validate

crs$test <- NULL


# The following variable selections have been noted.

crs$input     <- c("age", "sex", "smoking", "drinking",
                   "cancer.type", "tumor.stage", "bmi", "mac", "tsf",
                   "hgs", "mamc", "cc", "asmi", "anorexia", "nausea",
                   "vomit", "mouth.sores", "constipation",
                   "diarrhea", "dry.mouth", "taste.changes",
                   "smell.changes", "disphagia", "early.satiety",
                   "abdominal.pain", "other.eating.symptoms",
                   "total.protein", "prealbumin", "albumin",
                   "transferrin", "urea.nitrogen", "creatinine",
                   "total.bilirubin", "direct.bilirubin", "alt",
                   "ast", "cholesterol", "glucose", "triglyceride",
                   "hdl", "ldl", "hemoglobin", "wbc", "rbc", "plt",
                   "neutrophil", "lymphocyte", "nlr",
                   "creactive.protein")

crs$numeric   <- c("age", "bmi", "mac", "tsf", "hgs", "mamc",
                   "cc", "asmi", "total.protein", "prealbumin",
                   "albumin", "transferrin", "urea.nitrogen",
                   "creatinine", "total.bilirubin",
                   "direct.bilirubin", "alt", "ast", "cholesterol",
                   "glucose", "triglyceride", "hdl", "ldl",
                   "hemoglobin", "wbc", "rbc", "plt", "neutrophil",
                   "lymphocyte", "nlr", "creactive.protein")

crs$categoric <- c("sex", "smoking", "drinking", "cancer.type",
                   "tumor.stage", "anorexia", "nausea", "vomit",
                   "mouth.sores", "constipation", "diarrhea",
                   "dry.mouth", "taste.changes", "smell.changes",
                   "disphagia", "early.satiety", "abdominal.pain",
                   "other.eating.symptoms")

crs$target    <- "cachexia"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- "weight.loss.percentage"
crs$weights   <- NULL


# Conditional inference tree. 

# Build a conditional tree using the party package.

library(party, quietly=TRUE)

# Build a ctree model.

crs$rpart <- ctree(cachexia ~ ., data=crs$dataset[crs$train,c(crs$input, crs$target)])

# Generate summary of the ctree model.

print(crs$rpart)

# Time taken: 0.49 secs

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(cachexia ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=6,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=50)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 21.60 secs

# Build a Random Forest model using the traditional approach.

set.seed(crv$seed)

crs$rf <- randomForest::randomForest(cachexia ~ .,
  data=crs$dataset[crs$train, c(crs$input, crs$target)], 
  ntree=500,
  mtry=7,
  importance=TRUE,
  na.action=randomForest::na.roughfix,
  replace=FALSE)

# Generate textual output of the 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted), quiet=TRUE)

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted), quiet=TRUE)FALSE

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 52.75 secs

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(cachexia) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 40.05 secs

# Regression model 

# Build a Regression model.

crs$glm <- glm(cachexia ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    family=binomial(link="logit"))

# Generate a textual view of the Linear model.

print(summary(crs$glm))

cat(sprintf("Log likelihood: %.3f (%d df)\n",
            logLik(crs$glm)[1],
            attr(logLik(crs$glm), "df")))

cat(sprintf("Null/Residual deviance difference: %.3f (%d df)\n",
            crs$glm$null.deviance-crs$glm$deviance,
            crs$glm$df.null-crs$glm$df.residual))

cat(sprintf("Chi-square p-value: %.8f\n",
            dchisq(crs$glm$null.deviance-crs$glm$deviance,
                   crs$glm$df.null-crs$glm$df.residual)))

cat(sprintf("Pseudo R-Square (optimistic): %.8f\n",
             cor(crs$glm$y, crs$glm$fitted.values)))

cat('\n==== ANOVA ====\n\n')
print(anova(crs$glm, test="Chisq"))
cat("\n")

# Time taken: 4.69 secs

# Neural Network 

# Build a neural network model using the nnet package.

library(nnet, quietly=TRUE)

# Build the NNet model.

set.seed(199)
crs$nnet <- nnet(as.factor(cachexia) ~ .,
    data=crs$dataset[crs$train,c(crs$input, crs$target)],
    size=10, skip=TRUE, MaxNWts=10000, trace=FALSE, maxit=100)

# Print the results of the modelling.

cat(sprintf("A %s network with %d weights.\n",
    paste(crs$nnet$n, collapse="-"),
    length(crs$nnet$wts)))
cat(sprintf("Inputs: %s.\n",
    paste(crs$nnet$coefnames, collapse=", ")))
cat(sprintf("Output: %s.\n",
    names(attr(crs$nnet$terms, "dataClasses"))[1]))
cat(sprintf("Sum of Squares Residuals: %.4f.\n",
    sum(residuals(crs$nnet) ^ 2)))
cat("\n")
print(summary(crs$nnet))
cat('\n')

# Time taken: 0.83 secs

# Evaluate model performance on the validation dataset. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the rpart model on dataset.csv [validate].

crs$pr <- sapply(party::treeresponse(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)]), function(x) x[2])

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Decision Tree dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ada model on dataset.csv [validate].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Extreme Boost dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the rf model on dataset.csv [validate].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]),
    type    = "prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Random Forest dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ksvm model on dataset.csv [validate].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]),
    type    = "probabilities")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve SVM dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the glm model on dataset.csv [validate].

crs$pr <- predict(crs$glm, 
   type    = "response",
   newdata = crs$dataset[crs$validate, c(crs$input, crs$target)])

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Linear dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the nnet model on dataset.csv [validate].

crs$pr <- predict(crs$nnet, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Neural Net dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# Score the validation dataset. 

# Obtain probability scores for the Decision Tree model on dataset.csv [validate].

crs$pr <- sapply(party::treeresponse(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input)]), function(x) x[2])

# Obtain probability scores for the Extreme Boost model on dataset.csv [validate].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input)], type="prob")[,2]

# Obtain probability scores for the Random Forest model on dataset.csv [validate].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input)]),
    type    = "prob")[,2]

# Obtain probability scores for the SVM model on dataset.csv [validate].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input)]),
    type    = "probabilities")[,2]

# Obtain probability scores for the Linear model on dataset.csv [validate].

crs$pr <- predict(crs$glm, 
   type    = "response",
   newdata = crs$dataset[crs$validate, c(crs$input)])

# Obtain probability scores for the Neural Net model on dataset.csv [validate].

crs$pr <- predict(crs$nnet, newdata=crs$dataset[crs$validate, c(crs$input)])

# Extract the relevant variables from the dataset.

sdata <- crs$dataset[crs$validate,]

# Output the combined data.

write.csv(cbind(sdata, crs$pr), file="F:\Desktop\dataset_validate_prob.csv", row.names=FALSE)

# Rename the probability as "ap_model" in Excel, read the file into environment

dataset <- read.csv("F:\Desktop\dataset_validate_prob.csv", header=TRUE)

# Plot the ROC curves and compare the AUCs

library(pROC)

curve1 <- roc(dataset$cachexia,dataset$ap_rpart,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve2 <- roc(dataset$cachexia,dataset$ap_ada,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve3 <- roc(dataset$cachexia,dataset$ap_rf,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve4 <- roc(dataset$cachexia,dataset$ap_ksvm,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve5 <- roc(dataset$cachexia,dataset$ap_glm,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve6 <- roc(dataset$cachexia,dataset$ap_nnet,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)

# Draw curve 1
plot(curve1, print.auc=TRUE, 
     col='#CC0000FF', 
     auc.polygon=FALSE, 
     auc.polygon.col="lightblue", 
     grid=c(0.1, 0.1), 
     grid.col=c("gray","gray"), 
     max.auc.polygon=FALSE, 
     print.thres=FALSE, 
     main = "ROC curve", 
     print.auc.x=0.5, 
     print.auc.y=0.6, 
     smooth=TRUE,
     lty=1,
     legacy.axes=T)

# Draw other curves
plot(curve2,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.5,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=2,col="#CCCC00FF")
plot(curve3,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.4,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=3,col="#00CC00FF")
plot(curve4,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.3,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=4,col="#00CCCCFF")
plot(curve5,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.2,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=5,col="#0000CCFF")
plot(curve6,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.1,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=6,col="#CC00CCFF")

legend("bottomleft", legend=c("DT","ADA","RF","SVM","LR","NNET"),col=rainbow(6, 1, .8), lty=1:6)

# Compare two ROC curves
roc.test(curve5, curve1, reuse.auc=FALSE)
roc.test(curve5, curve2, reuse.auc=FALSE)
roc.test(curve5, curve3, reuse.auc=FALSE)
roc.test(curve5, curve4, reuse.auc=FALSE)
roc.test(curve5, curve6, reuse.auc=FALSE)

# Indicate the train/validation information in the overall dataset with Excel
# Read the overall dataset

all <- read.csv("F:\Desktop\dataset.csv", header=TRUE)

# Creat the training set

dataset <- as.data.frame(all[train,])

attach(dataset)

# To determine the relative variable importance
library(ggplot2)
library(caret)

# Control parameters

control = trainControl(method = "repeatedcv", number = 10 , repeats = 5)

# Train models
ctree = train(cachexia~.,data = dataset, method = "ctree",preProcess = "scale", trControl = control)
rf = train(cachexia~.,data = dataset, method = "rf", preProcess = "scale", trControl = control)
ada = train(cachexia~.,data = dataset, method = "adaboost", preProcess = "scale", trControl = control)
svmRadial = train(cachexia~.,data = dataset, method = "svmRadial", preProcess = "scale", trControl = control)
glm = train(cachexia~.,data = dataset, method = "glm", preProcess = "scale", trControl = control)
nnet = train(cachexia~.,data = dataset, method = "nnet", preProcess = "scale", trControl = control)

# Calculate variable importance for each model
ctree_importance = varImp(ctree)
rf_importance = varImp(rf)
ada_importance = varImp(ada)
svmRadial_importance = varImp(svmRadial)
glm_importance = varImp(glm)
nnet_importance = varImp(nnet)

# Show variable importance for each model
plot(ctree_importance)
plot(rf_importance)
plot(ada_importance)
plot(svmRadial_importance)
plot(glm_importance)
plot(nnet_importance)

#==================================================================
# Re-train models with selected features

# so that results are repeatable.

crv$seed <- 8

# Load a dataset from file.

fname         <- "file:///F:/Desktop/dataset.csv" ## Overall dataset
crs$dataset <- read.csv(fname,
                        na.strings=c(".", "NA", "", "?"),
                        strip.white=TRUE, encoding="UTF-8")

# Build the train/validate/test datasets.

# nobs=12774 train=9580 validate=3194 test=0

set.seed(8)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.75*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) ->
crs$validate

crs$test <- NULL

# The following three models have the same input variables, train them first
# The following variable selections have been noted.

crs$input     <- c("cancer.type", "bmi", "mac", "tsf", "hgs",
                   "mamc", "cc", "asmi", "total.protein",
                   "prealbumin", "albumin", "hemoglobin", "rbc",
                   "nlr", "creactive.protein")

crs$numeric   <- c("bmi", "mac", "tsf", "hgs", "mamc", "cc",
                   "asmi", "total.protein", "prealbumin", "albumin",
                   "hemoglobin", "rbc", "nlr", "creactive.protein")

crs$categoric <- "cancer.type"

crs$target    <- "cachexia"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("age", "sex", "smoking", "drinking", "tumor.stage", "weight.loss.percentage", "anorexia", "nausea", "vomit", "mouth.sores", "constipation", "diarrhea", "dry.mouth", "taste.changes", "smell.changes", "disphagia", "early.satiety", "abdominal.pain", "other.eating.symptoms", "transferrin", "urea.nitrogen", "creatinine", "total.bilirubin", "direct.bilirubin", "alt", "ast", "cholesterol", "glucose", "triglyceride", "hdl", "ldl", "wbc", "plt", "neutrophil", "lymphocyte")
crs$weights   <- NULL

# Conditional inference tree. 

# Build a conditional tree using the party package.

library(party, quietly=TRUE)

# Build a ctree model.

crs$rpart <- ctree(cachexia ~ ., data=crs$dataset[crs$train,c(crs$input, crs$target)])

# Generate summary of the ctree model.

print(crs$rpart)

# Time taken: 0.15 secs

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(cachexia ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=6,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=50)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 9.53 secs

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(cachexia) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 26.19 secs

# Evaluate model performance on the validation dataset. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the rpart model on dataset.csv [validate].

crs$pr <- sapply(party::treeresponse(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)]), function(x) x[2])

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Decision Tree dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ada model on dataset.csv [validate].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Extreme Boost dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ksvm model on dataset.csv [validate].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]),
    type    = "probabilities")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve SVM dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# Score the validation dataset. 

# Obtain probability scores for the Decision Tree model on dataset.csv [validate].

crs$pr <- sapply(party::treeresponse(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input)]), function(x) x[2])

# Obtain probability scores for the Extreme Boost model on dataset.csv [validate].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input)], type="prob")[,2]

# Obtain probability scores for the SVM model on dataset.csv [validate].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input)]),
    type    = "probabilities")[,2]

# Extract the relevant variables from the dataset.

sdata <- crs$dataset[crs$validate,]

# Output the combined data.

write.csv(cbind(sdata, crs$pr), file="F:\Desktop\dataset_validate_prob_three_models.csv", row.names=FALSE)

#============================================================================
# Then train the Random forest

# so that results are repeatable.

crv$seed <- 8

# Load a dataset from file.

fname         <- "file:///F:/Desktop/dataset.csv" ## Overall dataset
crs$dataset <- read.csv(fname,
                        na.strings=c(".", "NA", "", "?"),
                        strip.white=TRUE, encoding="UTF-8")

# Build the train/validate/test datasets.

# nobs=12774 train=9580 validate=3194 test=0

set.seed(8)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.75*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) ->
crs$validate

crs$test <- NULL


# The following variable selections have been noted.

crs$input     <- c("bmi", "mac", "tsf", "hgs", "mamc", "cc",
                   "asmi", "total.protein", "prealbumin", "albumin",
                   "hemoglobin", "rbc", "plt", "nlr",
                   "creactive.protein")

crs$numeric   <- c("bmi", "mac", "tsf", "hgs", "mamc", "cc",
                   "asmi", "total.protein", "prealbumin", "albumin",
                   "hemoglobin", "rbc", "plt", "nlr",
                   "creactive.protein")

crs$categoric <- NULL

crs$target    <- "cachexia"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("age", "sex", "smoking", "drinking", "cancer.type", "tumor.stage", "weight.loss.percentage", "anorexia", "nausea", "vomit", "mouth.sores", "constipation", "diarrhea", "dry.mouth", "taste.changes", "smell.changes", "disphagia", "early.satiety", "abdominal.pain", "other.eating.symptoms", "transferrin", "urea.nitrogen", "creatinine", "total.bilirubin", "direct.bilirubin", "alt", "ast", "cholesterol", "glucose", "triglyceride", "hdl", "ldl", "wbc", "neutrophil", "lymphocyte")
crs$weights   <- NULL

# Build a Random Forest model using the traditional approach.

set.seed(crv$seed)

crs$rf <- randomForest::randomForest(cachexia ~ .,
  data=crs$dataset[crs$train, c(crs$input, crs$target)], 
  ntree=500,
  mtry=3,
  importance=TRUE,
  na.action=randomForest::na.roughfix,
  replace=FALSE)

# Generate textual output of the 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted), quiet=TRUE)

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted), quiet=TRUE)FALSE

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 19.58 secs

# Evaluate model performance on the validation dataset. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the rf model on dataset.csv [validate].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]),
    type    = "prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Random Forest dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# Score the validation dataset. 

# Obtain probability scores for the Random Forest model on dataset.csv [validate].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input)]),
    type    = "prob")[,2]

# Extract the relevant variables from the dataset.

sdata <- crs$dataset[crs$validate,]

# Output the combined data.

write.csv(cbind(sdata, crs$pr), file="F:\Desktop\dataset_validate_score_rf.csv", row.names=FALSE)

#============================================================================
# Then train the Logistic regression model (glm)

# so that results are repeatable.

crv$seed <- 8

# Load a dataset from file.

fname         <- "file:///F:/Desktop/dataset.csv" ## Overall dataset
crs$dataset <- read.csv(fname,
                        na.strings=c(".", "NA", "", "?"),
                        strip.white=TRUE, encoding="UTF-8")


#============================================================================
# Then train the logistic regression

# so that results are repeatable.

crv$seed <- 8

# Load a dataset from file.

fname         <- "file:///F:/Desktop/dataset.csv" ## Overall dataset
crs$dataset <- read.csv(fname,
                        na.strings=c(".", "NA", "", "?"),
                        strip.white=TRUE, encoding="UTF-8")

# Build the train/validate/test datasets.

# nobs=12774 train=9580 validate=3194 test=0

set.seed(8)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.75*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) ->
crs$validate

crs$test <- NULL


# The following variable selections have been noted.

crs$input     <- c("age", "sex", "cancer.type", "bmi", "asmi",
                   "anorexia", "vomit", "diarrhea", "early.satiety",
                   "abdominal.pain", "other.eating.symptoms",
                   "direct.bilirubin", "ast", "hemoglobin", "plt")

crs$numeric   <- c("age", "bmi", "asmi", "direct.bilirubin",
                   "ast", "hemoglobin", "plt")

crs$categoric <- c("sex", "cancer.type", "anorexia", "vomit",
                   "diarrhea", "early.satiety", "abdominal.pain",
                   "other.eating.symptoms")

crs$target    <- "cachexia"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("smoking", "drinking", "tumor.stage", "weight.loss.percentage", "mac", "tsf", "hgs", "mamc", "cc", "nausea", "mouth.sores", "constipation", "dry.mouth", "taste.changes", "smell.changes", "disphagia", "total.protein", "prealbumin", "albumin", "transferrin", "urea.nitrogen", "creatinine", "total.bilirubin", "alt", "cholesterol", "glucose", "triglyceride", "hdl", "ldl", "wbc", "rbc", "neutrophil", "lymphocyte", "nlr", "creactive.protein")
crs$weights   <- NULL

# Regression model 

# Build a Regression model.

crs$glm <- glm(cachexia ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    family=binomial(link="logit"))

# Generate a textual view of the Linear model.

print(summary(crs$glm))

cat(sprintf("Log likelihood: %.3f (%d df)\n",
            logLik(crs$glm)[1],
            attr(logLik(crs$glm), "df")))

cat(sprintf("Null/Residual deviance difference: %.3f (%d df)\n",
            crs$glm$null.deviance-crs$glm$deviance,
            crs$glm$df.null-crs$glm$df.residual))

cat(sprintf("Chi-square p-value: %.8f\n",
            dchisq(crs$glm$null.deviance-crs$glm$deviance,
                   crs$glm$df.null-crs$glm$df.residual)))

cat(sprintf("Pseudo R-Square (optimistic): %.8f\n",
             cor(crs$glm$y, crs$glm$fitted.values)))

cat('\n==== ANOVA ====\n\n')
print(anova(crs$glm, test="Chisq"))
cat("\n")

# Time taken: 0.82 secs

# Evaluate model performance on the validation dataset. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the glm model on dataset.csv [validate].

crs$pr <- predict(crs$glm, 
   type    = "response",
   newdata = crs$dataset[crs$validate, c(crs$input, crs$target)])

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Linear dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# Score the validation dataset. 

# Obtain probability scores for the Linear model on dataset.csv [validate].

crs$pr <- predict(crs$glm, 
   type    = "response",
   newdata = crs$dataset[crs$validate, c(crs$input)])

# Extract the relevant variables from the dataset.

sdata <- crs$dataset[crs$validate,]

# Output the combined data.

write.csv(cbind(sdata, crs$pr), file="F:\Desktop\dataset_validate_score_lr.csv", row.names=FALSE)

#============================================================================
# Then train the neural network

# so that results are repeatable.

crv$seed <- 8

# Load a dataset from file.

fname         <- "file:///F:/Desktop/dataset.csv" ## Overall dataset
crs$dataset <- read.csv(fname,
                        na.strings=c(".", "NA", "", "?"),
                        strip.white=TRUE, encoding="UTF-8")

# Build the train/validate/test datasets.

# nobs=12774 train=9580 validate=3194 test=0

set.seed(8)

crs$nobs <- nrow(crs$dataset)

crs$train <- sample(crs$nobs, 0.75*crs$nobs)

crs$nobs %>%
  seq_len() %>%
  setdiff(crs$train) ->
crs$validate

crs$test <- NULL


# The following variable selections have been noted.

crs$input     <- c("sex", "tumor.stage", "bmi", "hgs", "asmi",
                   "anorexia", "vomit", "mouth.sores",
                   "abdominal.pain", "total.bilirubin",
                   "direct.bilirubin", "alt", "triglyceride", "ldl",
                   "neutrophil")

crs$numeric   <- c("bmi", "hgs", "asmi", "total.bilirubin",
                   "direct.bilirubin", "alt", "triglyceride", "ldl",
                   "neutrophil")

crs$categoric <- c("sex", "tumor.stage", "anorexia", "vomit",
                   "mouth.sores", "abdominal.pain")

crs$target    <- "cachexia"
crs$risk      <- NULL
crs$ident     <- NULL
crs$ignore    <- c("age", "smoking", "drinking", "cancer.type", "weight.loss.percentage", "mac", "tsf", "mamc", "cc", "nausea", "constipation", "diarrhea", "dry.mouth", "taste.changes", "smell.changes", "disphagia", "early.satiety", "other.eating.symptoms", "total.protein", "prealbumin", "albumin", "transferrin", "urea.nitrogen", "creatinine", "ast", "cholesterol", "glucose", "hdl", "hemoglobin", "wbc", "rbc", "plt", "lymphocyte", "nlr", "creactive.protein")
crs$weights   <- NULL

# Neural Network 

# Build a neural network model using the nnet package.

library(nnet, quietly=TRUE)

# Build the NNet model.

set.seed(199)
crs$nnet <- nnet(as.factor(cachexia) ~ .,
    data=crs$dataset[crs$train,c(crs$input, crs$target)],
    size=10, skip=TRUE, MaxNWts=10000, trace=FALSE, maxit=100)

# Print the results of the modelling.

cat(sprintf("A %s network with %d weights.\n",
    paste(crs$nnet$n, collapse="-"),
    length(crs$nnet$wts)))
cat(sprintf("Inputs: %s.\n",
    paste(crs$nnet$coefnames, collapse=", ")))
cat(sprintf("Output: %s.\n",
    names(attr(crs$nnet$terms, "dataClasses"))[1]))
cat(sprintf("Sum of Squares Residuals: %.4f.\n",
    sum(residuals(crs$nnet) ^ 2)))
cat("\n")
print(summary(crs$nnet))
cat('\n')

# Time taken: 2.90 secs

# Evaluate model performance on the validation dataset. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the nnet model on dataset.csv [validate].

crs$pr <- predict(crs$nnet, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Neural Net dataset.csv [validate] cachexia")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$cachexia)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# Score the validation dataset. 

# Obtain probability scores for the Neural Net model on dataset.csv [validate].

crs$pr <- predict(crs$nnet, newdata=crs$dataset[crs$validate, c(crs$input)])

# Extract the relevant variables from the dataset.

sdata <- crs$dataset[crs$validate,]

# Output the combined data.

write.csv(cbind(sdata, crs$pr), file="F:\Desktop\dataset_validate_score_nnet.csv", row.names=FALSE)

# ROC curves and AUC comparison for the simplified models
# Combine the predicted probability for each smodel in Excel before the analysis

library(pROC)

curve1 <- roc(dataset$cachexia,dataset$ap_rpart,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve2 <- roc(dataset$cachexia,dataset$ap_ada,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve3 <- roc(dataset$cachexia,dataset$ap_rf,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve4 <- roc(dataset$cachexia,dataset$ap_ksvm,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve5 <- roc(dataset$cachexia,dataset$ap_glm,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)
curve6 <- roc(dataset$cachexia,dataset$ap_nnet,ci=TRUE, boot.n=100, ci.alpha=0.9, stratified=FALSE)

# Draw curve 1
plot(curve1, print.auc=TRUE, 
     col='#CC0000FF', 
     auc.polygon=FALSE, 
     auc.polygon.col="lightblue", 
     grid=c(0.1, 0.1), 
     grid.col=c("gray","gray"), 
     max.auc.polygon=FALSE, 
     print.thres=FALSE, 
     main = "ROC curve", 
     print.auc.x=0.5, 
     print.auc.y=0.6, 
     smooth=TRUE,
     lty=1,
     legacy.axes=T)

# Draw other curves
plot(curve2,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.5,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=2,col="#CCCC00FF")
plot(curve3,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.4,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=3,col="#00CC00FF")
plot(curve4,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.3,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=4,col="#00CCCCFF")
plot(curve5,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.2,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=5,col="#0000CCFF")
plot(curve6,add=T,print.auc=TRUE,print.auc.x=0.5,print.auc.y=0.1,ci=TRUE, boot.n=100, ci.alpha=0.9,print.thres=FALSE,lty=6,col="#CC00CCFF")

legend("bottomleft", legend=c("DT","ADA","RF","SVM","LR","NNET"),col=rainbow(6, 1, .8), lty=1:6)

# Compare two ROC curves
roc.test(curve5, curve1, reuse.auc=FALSE)
roc.test(curve5, curve2, reuse.auc=FALSE)
roc.test(curve5, curve3, reuse.auc=FALSE)
roc.test(curve5, curve4, reuse.auc=FALSE)
roc.test(curve5, curve6, reuse.auc=FALSE)

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

